{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY1-KtGGxr2T"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense , Dropout\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "decYfR6syAkS",
        "outputId": "b0a5c5d8-0761-4d1b-89be-7608f05cc5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCyqoXQg4Hr1"
      },
      "outputs": [],
      "source": [
        "# Define paths to training and testing datasets\n",
        "train_path = '/content/drive/MyDrive/tomato/train'\n",
        "test_path = '/content/drive/MyDrive/tomato/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZmsagOUX7u2"
      },
      "outputs": [],
      "source": [
        "train_gen = ImageDataGenerator(rescale=(1./255),horizontal_flip=True,shear_range=0.2,zoom_range = 0.2)\n",
        "test_gen = ImageDataGenerator(rescale=(1./255))  #--> (0 to 255) convert to (0 to 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3bf8LufX-yr",
        "outputId": "2ec8d32a-cee2-4547-c604-37ee88515e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8999 images belonging to 9 classes.\n",
            "Found 900 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "train = train_gen.flow_from_directory( '/content/drive/MyDrive/tomato/train',\n",
        "                                      target_size=(120, 120),\n",
        "                                      class_mode='categorical',\n",
        "                                      subset='training',\n",
        "                                      batch_size=9)\n",
        "test = test_gen.flow_from_directory('/content/drive/MyDrive/tomato/val',\n",
        "                                    target_size=(120, 120),\n",
        "                                      class_mode='categorical',\n",
        "                                      batch_size=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuHwxETtYLmL",
        "outputId": "3963d424-797f-4189-f951-b2a4e24f2eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Tomato___Bacterial_spot': 0,\n",
              " 'Tomato___Early_blight': 1,\n",
              " 'Tomato___Late_blight': 2,\n",
              " 'Tomato___Leaf_Mold': 3,\n",
              " 'Tomato___Septoria_leaf_spot': 4,\n",
              " 'Tomato___Target_Spot': 5,\n",
              " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 6,\n",
              " 'Tomato___Tomato_mosaic_virus': 7,\n",
              " 'Tomato___healthy': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "train.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI-75ktJYSh4"
      },
      "outputs": [],
      "source": [
        "# CNN model\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,BatchNormalization,GlobalAveragePooling2D,Activation\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9g3OOhrYWYI",
        "outputId": "2d272292-cf63-438f-df4d-5880d9bb9ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_______________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 120, 120, 64)      4864      \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 120, 120, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 120, 120, 64)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 120, 120, 64)      102464    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 30, 30, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 7, 7, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 256)         1605888   \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 4, 4, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 2, 2, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 2, 2, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 1, 1, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 9)                 2313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6524105 (24.89 MB)\n",
            "Trainable params: 6517449 (24.86 MB)\n",
            "Non-trainable params: 6656 (26.00 KB)\n",
            "_______________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Block 0\n",
        "model.add(Conv2D(64, (5, 5), strides=1, padding=\"same\", input_shape=(120, 120, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(64, (5, 5), strides=1, padding=\"same\"))\n",
        "model.add(MaxPooling2D((4, 4)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(128, (3, 3), strides=2, padding=\"same\"))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.1))  # Adjust dropout rate\n",
        "\n",
        "# Block 3\n",
        "model.add(Conv2D(256, (7, 7), strides=2, padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))  # Adjust dropout rate\n",
        "\n",
        "# Block 4\n",
        "model.add(Conv2D(512, (3, 3), strides=2, padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.25))  # Adjust dropout rate\n",
        "\n",
        "# Block 5\n",
        "model.add(Conv2D(512, (3, 3), strides=2, padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.15))  # Adjust dropout rate\n",
        "\n",
        "# Global Average Pooling\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(1024, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))  # Adjust dropout rate\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))  # Adjust dropout rate\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quHLLDAAYYg1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pb0KoaDZOWS"
      },
      "outputs": [],
      "source": [
        "#performing early stopping to avoid overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 20, verbose = 1, restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KnFMcxNbLVl",
        "outputId": "d48ff944-f53b-46eb-d275-fb31b56a37e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 2034s 2s/step - loss: 1.8471 - accuracy: 0.3965 - val_loss: 3.8962 - val_accuracy: 0.3056\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 74s 74ms/step - loss: 1.1012 - accuracy: 0.6186 - val_loss: 1.7080 - val_accuracy: 0.4989\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.8569 - accuracy: 0.7099 - val_loss: 0.7058 - val_accuracy: 0.7556\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.7779 - accuracy: 0.7409 - val_loss: 0.8932 - val_accuracy: 0.6800\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.6912 - accuracy: 0.7691 - val_loss: 2.7506 - val_accuracy: 0.4311\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.6410 - accuracy: 0.7870 - val_loss: 0.4138 - val_accuracy: 0.8633\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.5910 - accuracy: 0.8040 - val_loss: 1.7992 - val_accuracy: 0.5289\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 73s 73ms/step - loss: 0.5628 - accuracy: 0.8156 - val_loss: 1.5661 - val_accuracy: 0.5700\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.5267 - accuracy: 0.8276 - val_loss: 1.1856 - val_accuracy: 0.6578\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.4774 - accuracy: 0.8489 - val_loss: 0.9353 - val_accuracy: 0.7033\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.4306 - accuracy: 0.8598 - val_loss: 0.7454 - val_accuracy: 0.7444\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3902 - accuracy: 0.8729 - val_loss: 1.1467 - val_accuracy: 0.6633\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.3762 - accuracy: 0.8770 - val_loss: 0.4079 - val_accuracy: 0.8711\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 74s 74ms/step - loss: 0.3270 - accuracy: 0.8929 - val_loss: 0.4534 - val_accuracy: 0.8444\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 74s 74ms/step - loss: 0.3102 - accuracy: 0.8978 - val_loss: 0.6700 - val_accuracy: 0.7833\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3016 - accuracy: 0.9031 - val_loss: 0.1676 - val_accuracy: 0.9422\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 72s 71ms/step - loss: 0.2723 - accuracy: 0.9123 - val_loss: 0.2810 - val_accuracy: 0.8944\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2506 - accuracy: 0.9233 - val_loss: 0.4160 - val_accuracy: 0.8556\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2323 - accuracy: 0.9282 - val_loss: 0.2550 - val_accuracy: 0.9211\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.2327 - accuracy: 0.9270 - val_loss: 0.4649 - val_accuracy: 0.8444\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2081 - accuracy: 0.9335 - val_loss: 0.3691 - val_accuracy: 0.8822\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2130 - accuracy: 0.9360 - val_loss: 0.2867 - val_accuracy: 0.8967\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1899 - accuracy: 0.9412 - val_loss: 0.1973 - val_accuracy: 0.9356\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1929 - accuracy: 0.9382 - val_loss: 0.3606 - val_accuracy: 0.8800\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1798 - accuracy: 0.9444 - val_loss: 0.1274 - val_accuracy: 0.9567\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1591 - accuracy: 0.9509 - val_loss: 0.2496 - val_accuracy: 0.9167\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1643 - accuracy: 0.9481 - val_loss: 0.1574 - val_accuracy: 0.9433\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1895 - accuracy: 0.9412 - val_loss: 0.6870 - val_accuracy: 0.7989\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 72s 71ms/step - loss: 0.1462 - accuracy: 0.9552 - val_loss: 0.2715 - val_accuracy: 0.9122\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1356 - accuracy: 0.9583 - val_loss: 0.1146 - val_accuracy: 0.9533\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1412 - accuracy: 0.9561 - val_loss: 0.2100 - val_accuracy: 0.9367\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1564 - accuracy: 0.9524 - val_loss: 0.2588 - val_accuracy: 0.9133\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1380 - accuracy: 0.9574 - val_loss: 0.3223 - val_accuracy: 0.8933\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1345 - accuracy: 0.9581 - val_loss: 0.1627 - val_accuracy: 0.9400\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1158 - accuracy: 0.9640 - val_loss: 1.6902 - val_accuracy: 0.6211\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1203 - accuracy: 0.9631 - val_loss: 0.1925 - val_accuracy: 0.9333\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1577 - accuracy: 0.9537 - val_loss: 0.2714 - val_accuracy: 0.9144\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1075 - accuracy: 0.9690 - val_loss: 0.1148 - val_accuracy: 0.9622\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1200 - accuracy: 0.9648 - val_loss: 0.0946 - val_accuracy: 0.9711\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1000 - accuracy: 0.9706 - val_loss: 1.1044 - val_accuracy: 0.7067\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1159 - accuracy: 0.9653 - val_loss: 0.1628 - val_accuracy: 0.9456\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1240 - accuracy: 0.9611 - val_loss: 0.1178 - val_accuracy: 0.9711\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1258 - accuracy: 0.9642 - val_loss: 0.1598 - val_accuracy: 0.9489\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1006 - accuracy: 0.9701 - val_loss: 0.2088 - val_accuracy: 0.9333\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0966 - accuracy: 0.9740 - val_loss: 0.1189 - val_accuracy: 0.9589\n",
            "Epoch 46/50\n",
            "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1376 - accuracy: 0.9601 - val_loss: 0.3087 - val_accuracy: 0.8900\n",
            "Epoch 47/50\n",
            "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1150 - accuracy: 0.9651 - val_loss: 0.2783 - val_accuracy: 0.9022\n",
            "Epoch 48/50\n",
            "1000/1000 [==============================] - 72s 71ms/step - loss: 0.0929 - accuracy: 0.9747 - val_loss: 0.1071 - val_accuracy: 0.9689\n",
            "Epoch 49/50\n",
            "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0932 - accuracy: 0.9736 - val_loss: 0.1360 - val_accuracy: 0.9522\n",
            "Epoch 50/50\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1113 - accuracy: 0.9682 - val_loss: 0.0921 - val_accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train,batch_size=10,validation_data=test,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/FinalDraft.h5')"
      ],
      "metadata": {
        "id": "8nigEMx-KW0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c18ccd4-b450-44f2-bc04-3fe174931012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via model.save(). This file format is considered legacy. We recommend using instead the native Keras format, e.g. model.save('my_model.keras').\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69lxNWMTj4KC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "22660493-4d33-42d7-e113-413d6f3ef9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": 
